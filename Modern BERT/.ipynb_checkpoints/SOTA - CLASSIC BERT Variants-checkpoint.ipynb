{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e26c312-8a54-4dbc-bd5d-2d935f8d9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449b3275-a509-45d5-a415-3faa06510a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, ModernBertForSequenceClassification\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7893e799-33bf-4ccf-a19b-8157127350ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fbafd28-6379-4d55-963c-79550ba0a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "class RoBERTaLargeBaselineClassifier:\n",
    "    def __init__(self, model_name=\"siebert/sentiment-roberta-large-english\"):\n",
    "        self.device = \"cpu\"\n",
    "\n",
    "        # Load tokenizer + fine-tuned RoBERTa-large sentiment classifier\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        # RoBERTa-large has 24 encoder layers\n",
    "        self.num_layers = self.model.config.num_hidden_layers  # = 24\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def classify(self, text, dataset_name=None):\n",
    "\n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "        )\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        # Forward pass through full model\n",
    "        outputs = self.model(**inputs)\n",
    "        logits = outputs.logits  # shape [1, 2]\n",
    "\n",
    "        # Softmax probabilities\n",
    "        probs = F.softmax(logits, dim=-1)[0]\n",
    "        conf, pred = torch.max(probs, dim=0)\n",
    "\n",
    "        # Return: predicted label, #layers used, confidence\n",
    "        return pred.item(), self.num_layers, conf.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f208a237-3bf9-4644-9323-1e578692f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "class DistilBERTBaselineClassifier:\n",
    "    def __init__(self, model_name=\"distilbert-base-uncased-finetuned-sst-2-english\"):\n",
    "        self.device = \"cpu\"\n",
    "\n",
    "        # Load tokenizer + fine-tuned DistilBERT sentiment classifier\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        # DistilBERT has 6 encoder layers\n",
    "        self.num_layers = self.model.config.num_hidden_layers  # = 6\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def classify(self, text, dataset_name=None):\n",
    "        # Tokenize text\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=False\n",
    "        )\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self.model(**inputs)\n",
    "        logits = outputs.logits  # shape [1, 2]\n",
    "\n",
    "        # Compute probabilities\n",
    "        probs = F.softmax(logits, dim=-1)[0]\n",
    "        conf, pred = torch.max(probs, dim=0)\n",
    "\n",
    "        # Baseline â†’ always uses full 6 layers\n",
    "        return pred.item(), self.num_layers, conf.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11f404c1-1a48-4294-bd68-13c41b288518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets once...\n",
      "\n",
      "Loading sst2...\n",
      "Loading imdb...\n",
      "Loading amazon_polarity...\n",
      "\n",
      "All datasets loaded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from evaluation.dataset_loaders.sst2 import load_sst2\n",
    "from evaluation.dataset_loaders.agnews import load_agnews\n",
    "from evaluation.dataset_loaders.amazon import load_amazon_polarity\n",
    "from evaluation.dataset_loaders.imdb import load_imdb\n",
    "from evaluation.dataset_loaders.dbpedia import load_dbpedia\n",
    "from evaluation.dataset_loaders.yanswers import load_yahoo\n",
    "\n",
    "dataset_loaders = [\n",
    "    (\"sst2\", load_sst2, \"classification\"),\n",
    "    (\"imdb\", load_imdb, \"classification\"),\n",
    "    (\"amazon_polarity\", load_amazon_polarity, \"classification\")\n",
    "]\n",
    "\n",
    "cached_datasets = {}\n",
    "print(\"Loading datasets once...\\n\")\n",
    "\n",
    "for name, loader, task in dataset_loaders:\n",
    "    print(f\"Loading {name}...\")\n",
    "    cached_datasets[name] = {\n",
    "        \"data\": loader(number=500),\n",
    "        \"task\": task\n",
    "    }\n",
    "\n",
    "print(\"\\nAll datasets loaded.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27c88862-88be-4b05-a563-6dab52f81bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract (text, label) from any format\n",
    "def extract_text_label(sample):\n",
    "    if isinstance(sample, dict):\n",
    "        if \"text\" in sample:\n",
    "            return sample[\"text\"], sample[\"label\"]\n",
    "        elif \"sentence\" in sample:\n",
    "            return sample[\"sentence\"], sample[\"label\"]\n",
    "        elif \"input_text\" in sample:\n",
    "            return sample[\"input_text\"], sample[\"label\"]\n",
    "        else:\n",
    "            raise ValueError(\"Unknown dict format:\", sample)\n",
    "\n",
    "    if isinstance(sample, (tuple, list)):\n",
    "        return sample[0], sample[1]\n",
    "\n",
    "    raise ValueError(\"Unknown sample format:\", sample)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_dataset(model, dataset, dataset_name):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    layers_used = []\n",
    "    total_tokens = 0\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for sample in dataset:\n",
    "        text, label = extract_text_label(sample)\n",
    "\n",
    "        pred, layer, conf = model.classify(text, dataset_name)\n",
    "\n",
    "        correct += (pred == label)\n",
    "        total += 1\n",
    "        layers_used.append(layer)\n",
    "\n",
    "        total_tokens += len(model.tokenizer(text)[\"input_ids\"])\n",
    "\n",
    "    end = time.time()\n",
    "    latency = (end - start) / total\n",
    "\n",
    "    return {\n",
    "        \"metric\": \"accuracy\",\n",
    "        \"score\": correct / total,\n",
    "        \"avg_latency_sec\": latency,\n",
    "        \"tokens_per_sec\": total_tokens / (end - start),\n",
    "        \"avg_layers_used\": float(np.mean(layers_used)),\n",
    "        \"num_samples\": total\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f55be5-411f-4909-8554-a5456a36cd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BASELINE\n",
      "\n",
      "Testing BASELINE on sst2...\n",
      "sst2 {'metric': 'accuracy', 'score': 0.908, 'avg_latency_sec': 0.012505305767059325, 'tokens_per_sec': 1977.080805583049, 'avg_layers_used': 6.0, 'num_samples': 500}\n",
      "\n",
      "Testing BASELINE on imdb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb {'metric': 'accuracy', 'score': 0.872, 'avg_latency_sec': 0.03287814998626709, 'tokens_per_sec': 9068.57594251921, 'avg_layers_used': 6.0, 'num_samples': 500}\n",
      "\n",
      "Testing BASELINE on amazon_polarity...\n",
      "amazon_polarity {'metric': 'accuracy', 'score': 0.134, 'avg_latency_sec': 0.015406723499298097, 'tokens_per_sec': 6344.762402236493, 'avg_layers_used': 6.0, 'num_samples': 500}\n"
     ]
    }
   ],
   "source": [
    "results_table = []\n",
    "\n",
    "print(\"Running BASELINE DISTILBERT\")\n",
    "\n",
    "baseline_model = DistilBERTBaselineClassifier()\n",
    "\n",
    "# Print number of layers (for logging/reporting)\n",
    "print(\"DistilBERT model layers:\", baseline_model.num_layers)\n",
    "\n",
    "for name, meta in cached_datasets.items():\n",
    "    dataset = meta[\"data\"]\n",
    "    print(f\"\\nTesting BASELINE on {name}...\")\n",
    "\n",
    "    result = evaluate_dataset(baseline_model, dataset, name)\n",
    "    print(name, result)\n",
    "\n",
    "    results_table.append({\n",
    "        \"dataset\": name,\n",
    "        \"threshold\": None,\n",
    "        \"mode\": \"baseline\",\n",
    "        \"model\": \"Distil-BERT\",\n",
    "        \"metric\": result[\"metric\"],\n",
    "        \"score\": float(result[\"score\"]),\n",
    "        \"avg_latency_sec\": float(result[\"avg_latency_sec\"]),\n",
    "        \"tokens_per_sec\": float(result[\"tokens_per_sec\"]),\n",
    "        \"avg_layers_used\": float(result[\"avg_layers_used\"]),\n",
    "        \"num_samples\": int(result[\"num_samples\"]),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e7b2510-7eb2-4156-b4a6-6fe34b2a940d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BASELINE ROBERTA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325b5f6aa5724d6d9bbc47374c3e6ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/256 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f917dc6ebacf4c4387ae174f8effbf99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1e7acaf13346e6babca82fd6699a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8cba4f6a6a47589897aff9ee7b0704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a911f74d00134aefbed36f0eae21fe70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c362829bab40289c4a79a662238d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35f6c3cd9b84ae9a2bbabfc2ebe1956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing BASELINE on sst2...\n",
      "sst2 {'metric': 'accuracy', 'score': 0.906, 'avg_latency_sec': 0.059351471900939944, 'tokens_per_sec': 430.8907459394446, 'avg_layers_used': 24.0, 'num_samples': 500}\n",
      "\n",
      "Testing BASELINE on imdb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb {'metric': 'accuracy', 'score': 0.946, 'avg_latency_sec': 0.21600387859344483, 'tokens_per_sec': 1324.531771665523, 'avg_layers_used': 24.0, 'num_samples': 500}\n",
      "\n",
      "Testing BASELINE on amazon_polarity...\n",
      "amazon_polarity {'metric': 'accuracy', 'score': 0.04, 'avg_latency_sec': 0.09732852172851562, 'tokens_per_sec': 981.8088089999533, 'avg_layers_used': 24.0, 'num_samples': 500}\n"
     ]
    }
   ],
   "source": [
    "print(\"Running BASELINE ROBERTA\")\n",
    "\n",
    "baseline_model_roberta = RoBERTaLargeBaselineClassifier()\n",
    "\n",
    "print(\"RoBERTa Large model layers:\", baseline_model.num_layers)\n",
    "\n",
    "for name, meta in cached_datasets.items():\n",
    "    dataset = meta[\"data\"]\n",
    "    print(f\"\\nTesting BASELINE on {name}...\")\n",
    "\n",
    "    result = evaluate_dataset(baseline_model_roberta, dataset, name)\n",
    "    print(name, result)\n",
    "\n",
    "    results_table.append({\n",
    "        \"dataset\": name,\n",
    "        \"threshold\": None,\n",
    "        \"mode\": \"baseline\",\n",
    "        \"model\": \"ROBERTA-Large\",\n",
    "        \"metric\": result[\"metric\"],\n",
    "        \"score\": float(result[\"score\"]),\n",
    "        \"avg_latency_sec\": float(result[\"avg_latency_sec\"]),\n",
    "        \"tokens_per_sec\": float(result[\"tokens_per_sec\"]),\n",
    "        \"avg_layers_used\": float(result[\"avg_layers_used\"]),\n",
    "        \"num_samples\": int(result[\"num_samples\"]),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7728d549-eb48-4e26-ae24-ab7ecdd40a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m4/8tn_t7fn3n999rq0tn3djx1w0000gn/T/ipykernel_1699/3662340674.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sort_values(\"score\", ascending=False))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>threshold</th>\n",
       "      <th>mode</th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "      <th>avg_latency_sec</th>\n",
       "      <th>tokens_per_sec</th>\n",
       "      <th>avg_layers_used</th>\n",
       "      <th>num_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon_polarity</td>\n",
       "      <td>None</td>\n",
       "      <td>baseline</td>\n",
       "      <td>Distil-BERT</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>6344.762402</td>\n",
       "      <td>6.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon_polarity</td>\n",
       "      <td>None</td>\n",
       "      <td>baseline</td>\n",
       "      <td>ROBERTA-Large</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.097329</td>\n",
       "      <td>981.808809</td>\n",
       "      <td>24.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imdb</td>\n",
       "      <td>None</td>\n",
       "      <td>baseline</td>\n",
       "      <td>ROBERTA-Large</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.216004</td>\n",
       "      <td>1324.531772</td>\n",
       "      <td>24.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imdb</td>\n",
       "      <td>None</td>\n",
       "      <td>baseline</td>\n",
       "      <td>Distil-BERT</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.032878</td>\n",
       "      <td>9068.575943</td>\n",
       "      <td>6.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sst2</td>\n",
       "      <td>None</td>\n",
       "      <td>baseline</td>\n",
       "      <td>Distil-BERT</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>1977.080806</td>\n",
       "      <td>6.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sst2</td>\n",
       "      <td>None</td>\n",
       "      <td>baseline</td>\n",
       "      <td>ROBERTA-Large</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.059351</td>\n",
       "      <td>430.890746</td>\n",
       "      <td>24.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset threshold      mode          model    metric  score  \\\n",
       "0  amazon_polarity      None  baseline    Distil-BERT  accuracy  0.134   \n",
       "1  amazon_polarity      None  baseline  ROBERTA-Large  accuracy  0.040   \n",
       "2             imdb      None  baseline  ROBERTA-Large  accuracy  0.946   \n",
       "3             imdb      None  baseline    Distil-BERT  accuracy  0.872   \n",
       "4             sst2      None  baseline    Distil-BERT  accuracy  0.908   \n",
       "5             sst2      None  baseline  ROBERTA-Large  accuracy  0.906   \n",
       "\n",
       "   avg_latency_sec  tokens_per_sec  avg_layers_used  num_samples  \n",
       "0         0.015407     6344.762402              6.0          500  \n",
       "1         0.097329      981.808809             24.0          500  \n",
       "2         0.216004     1324.531772             24.0          500  \n",
       "3         0.032878     9068.575943              6.0          500  \n",
       "4         0.012505     1977.080806              6.0          500  \n",
       "5         0.059351      430.890746             24.0          500  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(results_table)\n",
    "df_sorted = (\n",
    "    df.groupby(\"dataset\", group_keys=True)\n",
    "      .apply(lambda g: g.sort_values(\"score\", ascending=False))\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551b367-957b-425d-b412-47d849d1f3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
