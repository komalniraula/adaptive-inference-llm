{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e26c312-8a54-4dbc-bd5d-2d935f8d9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449b3275-a509-45d5-a415-3faa06510a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, ModernBertForSequenceClassification\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7893e799-33bf-4ccf-a19b-8157127350ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fbafd28-6379-4d55-963c-79550ba0a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "class RoBERTaLargeBaselineClassifier:\n",
    "    def __init__(self, model_name=\"siebert/sentiment-roberta-large-english\"):\n",
    "        self.device = \"cpu\"\n",
    "\n",
    "        # Load tokenizer + fine-tuned RoBERTa-large sentiment classifier\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        # RoBERTa-large has 24 encoder layers\n",
    "        self.num_layers = self.model.config.num_hidden_layers  # = 24\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def classify(self, text, dataset_name=None):\n",
    "\n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "        )\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        # Forward pass through full model\n",
    "        outputs = self.model(**inputs)\n",
    "        logits = outputs.logits  # shape [1, 2]\n",
    "\n",
    "        # Softmax probabilities\n",
    "        probs = F.softmax(logits, dim=-1)[0]\n",
    "        conf, pred = torch.max(probs, dim=0)\n",
    "\n",
    "        # Return: predicted label, #layers used, confidence\n",
    "        return pred.item(), self.num_layers, conf.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f208a237-3bf9-4644-9323-1e578692f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "class DistilBERTBaselineClassifier:\n",
    "    def __init__(self, model_name=\"distilbert-base-uncased-finetuned-sst-2-english\"):\n",
    "        self.device = \"cpu\"\n",
    "\n",
    "        # Load tokenizer + fine-tuned DistilBERT sentiment classifier\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        # DistilBERT has 6 encoder layers\n",
    "        self.num_layers = self.model.config.num_hidden_layers  # = 6\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def classify(self, text, dataset_name=None):\n",
    "        # Tokenize text\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=False\n",
    "        )\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self.model(**inputs)\n",
    "        logits = outputs.logits  # shape [1, 2]\n",
    "\n",
    "        # Compute probabilities\n",
    "        probs = F.softmax(logits, dim=-1)[0]\n",
    "        conf, pred = torch.max(probs, dim=0)\n",
    "\n",
    "        # Baseline â†’ always uses full 6 layers\n",
    "        return pred.item(), self.num_layers, conf.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f404c1-1a48-4294-bd68-13c41b288518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets once...\n",
      "\n",
      "Loading sst2...\n",
      "Loading imdb...\n",
      "Loading amazon_polarity...\n",
      "\n",
      "All datasets loaded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from evaluation.dataset_loaders.sst2 import load_sst2\n",
    "from evaluation.dataset_loaders.agnews import load_agnews\n",
    "from evaluation.dataset_loaders.amazon import load_amazon_polarity\n",
    "from evaluation.dataset_loaders.imdb import load_imdb\n",
    "from evaluation.dataset_loaders.dbpedia import load_dbpedia\n",
    "from evaluation.dataset_loaders.yanswers import load_yahoo\n",
    "\n",
    "dataset_loaders = [\n",
    "    (\"sst2\", load_sst2, \"classification\"),\n",
    "    (\"imdb\", load_imdb, \"classification\"),\n",
    "    (\"amazon_polarity\", load_amazon_polarity, \"classification\")\n",
    "]\n",
    "\n",
    "cached_datasets = {}\n",
    "print(\"Loading datasets once...\\n\")\n",
    "\n",
    "for name, loader, task in dataset_loaders:\n",
    "    print(f\"Loading {name}...\")\n",
    "    cached_datasets[name] = {\n",
    "        \"data\": loader(number=500),\n",
    "        \"task\": task\n",
    "    }\n",
    "\n",
    "print(\"\\nAll datasets loaded.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27c88862-88be-4b05-a563-6dab52f81bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract (text, label) from any format\n",
    "def extract_text_label(sample):\n",
    "    if isinstance(sample, dict):\n",
    "        if \"text\" in sample:\n",
    "            return sample[\"text\"], sample[\"label\"]\n",
    "        elif \"sentence\" in sample:\n",
    "            return sample[\"sentence\"], sample[\"label\"]\n",
    "        elif \"input_text\" in sample:\n",
    "            return sample[\"input_text\"], sample[\"label\"]\n",
    "        else:\n",
    "            raise ValueError(\"Unknown dict format:\", sample)\n",
    "\n",
    "    if isinstance(sample, (tuple, list)):\n",
    "        return sample[0], sample[1]\n",
    "\n",
    "    raise ValueError(\"Unknown sample format:\", sample)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_dataset(model, dataset, dataset_name):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    layers_used = []\n",
    "    total_tokens = 0\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for sample in dataset:\n",
    "        text, label = extract_text_label(sample)\n",
    "\n",
    "        pred, layer, conf = model.classify(text, dataset_name)\n",
    "\n",
    "        correct += (pred == label)\n",
    "        total += 1\n",
    "        layers_used.append(layer)\n",
    "\n",
    "        total_tokens += len(model.tokenizer(text)[\"input_ids\"])\n",
    "\n",
    "    end = time.time()\n",
    "    latency = (end - start) / total\n",
    "\n",
    "    return {\n",
    "        \"metric\": \"accuracy\",\n",
    "        \"score\": correct / total,\n",
    "        \"avg_latency_sec\": latency,\n",
    "        \"tokens_per_sec\": total_tokens / (end - start),\n",
    "        \"avg_layers_used\": float(np.mean(layers_used)),\n",
    "        \"num_samples\": total\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f55be5-411f-4909-8554-a5456a36cd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BASELINE DISTILBERT finetuned on SST2\n",
      "DistilBERT sst2 finetuned model layers: 6\n",
      "\n",
      "Testing BASELINE on sst2...\n",
      "sst2 {'metric': 'accuracy', 'score': 0.908, 'avg_latency_sec': 0.011286363601684571, 'tokens_per_sec': 2190.608142051153, 'avg_layers_used': 6.0, 'num_samples': 500}\n",
      "\n",
      "Testing BASELINE on imdb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb {'metric': 'accuracy', 'score': 0.872, 'avg_latency_sec': 0.03295257186889648, 'tokens_per_sec': 9048.094976812039, 'avg_layers_used': 6.0, 'num_samples': 500}\n",
      "\n",
      "Testing BASELINE on amazon_polarity...\n",
      "amazon_polarity {'metric': 'accuracy', 'score': 0.134, 'avg_latency_sec': 0.015561259746551514, 'tokens_per_sec': 6281.753636408681, 'avg_layers_used': 6.0, 'num_samples': 500}\n"
     ]
    }
   ],
   "source": [
    "results_table = []\n",
    "\n",
    "print(\"Running BASELINE DISTILBERT finetuned on SST2\")\n",
    "\n",
    "baseline_model = DistilBERTBaselineClassifier()\n",
    "\n",
    "# Print number of layers (for logging/reporting)\n",
    "print(\"DistilBERT sst2 finetuned model layers:\", baseline_model.num_layers)\n",
    "\n",
    "for name, meta in cached_datasets.items():\n",
    "    dataset = meta[\"data\"]\n",
    "    print(f\"\\nTesting BASELINE on {name}...\")\n",
    "\n",
    "    result = evaluate_dataset(baseline_model, dataset, name)\n",
    "    print(name, result)\n",
    "\n",
    "    results_table.append({\n",
    "        \"dataset\": name,\n",
    "        \"threshold\": None,\n",
    "        \"mode\": \"baseline\",\n",
    "        \"model\": \"Distil-BERT\",\n",
    "        \"metric\": result[\"metric\"],\n",
    "        \"score\": float(result[\"score\"]),\n",
    "        \"avg_latency_sec\": float(result[\"avg_latency_sec\"]),\n",
    "        \"tokens_per_sec\": float(result[\"tokens_per_sec\"]),\n",
    "        \"avg_layers_used\": float(result[\"avg_layers_used\"]),\n",
    "        \"num_samples\": int(result[\"num_samples\"]),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b52e27a7-9484-4f60-b5c2-9e81c54362da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BASELINE DISTILBERT uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT uncased model layers: 6\n",
      "\n",
      "Testing BASELINE on sst2...\n",
      "sst2 {'metric': 'accuracy', 'score': 0.908, 'avg_latency_sec': 0.010580691814422607, 'tokens_per_sec': 2336.7092089667103, 'avg_layers_used': 6.0, 'num_samples': 500}\n",
      "\n",
      "Testing BASELINE on imdb...\n",
      "imdb {'metric': 'accuracy', 'score': 0.872, 'avg_latency_sec': 0.03368844175338745, 'tokens_per_sec': 8850.453879186012, 'avg_layers_used': 6.0, 'num_samples': 500}\n",
      "\n",
      "Testing BASELINE on amazon_polarity...\n",
      "amazon_polarity {'metric': 'accuracy', 'score': 0.134, 'avg_latency_sec': 0.015547555923461914, 'tokens_per_sec': 6287.290457819684, 'avg_layers_used': 6.0, 'num_samples': 500}\n"
     ]
    }
   ],
   "source": [
    "results_table = []\n",
    "\n",
    "print(\"Running BASELINE DISTILBERT uncased\")\n",
    "\n",
    "baseline_model_distil_uncased = DistilBERTBaselineClassifier(model_name=\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "# Print number of layers (for logging/reporting)\n",
    "print(\"DistilBERT uncased model layers:\", baseline_model_distil_uncased.num_layers)\n",
    "\n",
    "for name, meta in cached_datasets.items():\n",
    "    dataset = meta[\"data\"]\n",
    "    print(f\"\\nTesting BASELINE on {name}...\")\n",
    "\n",
    "    result = evaluate_dataset(baseline_model, dataset, name)\n",
    "    print(name, result)\n",
    "\n",
    "    results_table.append({\n",
    "        \"dataset\": name,\n",
    "        \"threshold\": None,\n",
    "        \"mode\": \"baseline\",\n",
    "        \"model\": \"Distil-BERT\",\n",
    "        \"metric\": result[\"metric\"],\n",
    "        \"score\": float(result[\"score\"]),\n",
    "        \"avg_latency_sec\": float(result[\"avg_latency_sec\"]),\n",
    "        \"tokens_per_sec\": float(result[\"tokens_per_sec\"]),\n",
    "        \"avg_layers_used\": float(result[\"avg_layers_used\"]),\n",
    "        \"num_samples\": int(result[\"num_samples\"]),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e7b2510-7eb2-4156-b4a6-6fe34b2a940d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BASELINE ROBERTA\n",
      "RoBERTa Large model layers: 24\n",
      "\n",
      "Testing BASELINE on sst2...\n",
      "sst2 {'metric': 'accuracy', 'score': 0.906, 'avg_latency_sec': 0.05800025987625122, 'tokens_per_sec': 440.92905884498504, 'avg_layers_used': 24.0, 'num_samples': 500}\n",
      "\n",
      "Testing BASELINE on imdb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb {'metric': 'accuracy', 'score': 0.946, 'avg_latency_sec': 0.212664897441864, 'tokens_per_sec': 1345.3278065234624, 'avg_layers_used': 24.0, 'num_samples': 500}\n",
      "\n",
      "Testing BASELINE on amazon_polarity...\n",
      "amazon_polarity {'metric': 'accuracy', 'score': 0.04, 'avg_latency_sec': 0.09528836822509766, 'tokens_per_sec': 1002.8296399647163, 'avg_layers_used': 24.0, 'num_samples': 500}\n"
     ]
    }
   ],
   "source": [
    "print(\"Running BASELINE ROBERTA\")\n",
    "\n",
    "baseline_model_roberta = RoBERTaLargeBaselineClassifier()\n",
    "\n",
    "print(\"RoBERTa Large model layers:\", baseline_model_roberta.num_layers)\n",
    "\n",
    "for name, meta in cached_datasets.items():\n",
    "    dataset = meta[\"data\"]\n",
    "    print(f\"\\nTesting BASELINE on {name}...\")\n",
    "\n",
    "    result = evaluate_dataset(baseline_model_roberta, dataset, name)\n",
    "    print(name, result)\n",
    "\n",
    "    results_table.append({\n",
    "        \"dataset\": name,\n",
    "        \"threshold\": None,\n",
    "        \"mode\": \"baseline\",\n",
    "        \"model\": \"ROBERTA-Large\",\n",
    "        \"metric\": result[\"metric\"],\n",
    "        \"score\": float(result[\"score\"]),\n",
    "        \"avg_latency_sec\": float(result[\"avg_latency_sec\"]),\n",
    "        \"tokens_per_sec\": float(result[\"tokens_per_sec\"]),\n",
    "        \"avg_layers_used\": float(result[\"avg_layers_used\"]),\n",
    "        \"num_samples\": int(result[\"num_samples\"]),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7728d549-eb48-4e26-ae24-ab7ecdd40a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m4/8tn_t7fn3n999rq0tn3djx1w0000gn/T/ipykernel_3497/3662340674.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sort_values(\"score\", ascending=False))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>threshold</th>\n",
       "      <th>mode</th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "      <th>avg_latency_sec</th>\n",
       "      <th>tokens_per_sec</th>\n",
       "      <th>avg_layers_used</th>\n",
       "      <th>num_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon_polarity</td>\n",
       "      <td>None</td>\n",
       "      <td>baseline</td>\n",
       "      <td>Distil-BERT</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.015548</td>\n",
       "      <td>6287.290458</td>\n",
       "      <td>6.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon_polarity</td>\n",
       "      <td>None</td>\n",
       "      <td>baseline</td>\n",
       "      <td>ROBERTA-Large</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.095288</td>\n",
       "      <td>1002.829640</td>\n",
       "      <td>24.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imdb</td>\n",
       "      <td>None</td>\n",
       "      <td>baseline</td>\n",
       "      <td>ROBERTA-Large</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.212665</td>\n",
       "      <td>1345.327807</td>\n",
       "      <td>24.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imdb</td>\n",
       "      <td>None</td>\n",
       "      <td>baseline</td>\n",
       "      <td>Distil-BERT</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.033688</td>\n",
       "      <td>8850.453879</td>\n",
       "      <td>6.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sst2</td>\n",
       "      <td>None</td>\n",
       "      <td>baseline</td>\n",
       "      <td>Distil-BERT</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>2336.709209</td>\n",
       "      <td>6.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sst2</td>\n",
       "      <td>None</td>\n",
       "      <td>baseline</td>\n",
       "      <td>ROBERTA-Large</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>440.929059</td>\n",
       "      <td>24.0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset threshold      mode          model    metric  score  \\\n",
       "0  amazon_polarity      None  baseline    Distil-BERT  accuracy  0.134   \n",
       "1  amazon_polarity      None  baseline  ROBERTA-Large  accuracy  0.040   \n",
       "2             imdb      None  baseline  ROBERTA-Large  accuracy  0.946   \n",
       "3             imdb      None  baseline    Distil-BERT  accuracy  0.872   \n",
       "4             sst2      None  baseline    Distil-BERT  accuracy  0.908   \n",
       "5             sst2      None  baseline  ROBERTA-Large  accuracy  0.906   \n",
       "\n",
       "   avg_latency_sec  tokens_per_sec  avg_layers_used  num_samples  \n",
       "0         0.015548     6287.290458              6.0          500  \n",
       "1         0.095288     1002.829640             24.0          500  \n",
       "2         0.212665     1345.327807             24.0          500  \n",
       "3         0.033688     8850.453879              6.0          500  \n",
       "4         0.010581     2336.709209              6.0          500  \n",
       "5         0.058000      440.929059             24.0          500  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(results_table)\n",
    "df_sorted = (\n",
    "    df.groupby(\"dataset\", group_keys=True)\n",
    "      .apply(lambda g: g.sort_values(\"score\", ascending=False))\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551b367-957b-425d-b412-47d849d1f3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
