{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe704b7-a605-450f-9f87-4b337eb164ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this for to create your folder and save experiments\n",
    "#model_name = 'komal/gpt2-medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1_8ZEe6qNeVo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_8ZEe6qNeVo",
    "outputId": "0491534a-3377-4775-9807-2cdacad3acc2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define the persistent path on your Drive\n",
    "# IMPORTANT: This folder must exist in your Google Drive!\n",
    "PERSISTENT_BASE_DIR = f'/content/drive/MyDrive/Efficient_AI_Project/EarlyExit_Experiments/{model_name}'\n",
    "os.makedirs(PERSISTENT_BASE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f35dfa-e61e-456a-a8af-c0aa7959ccfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42f35dfa-e61e-456a-a8af-c0aa7959ccfa",
    "outputId": "a7768a11-f5ff-49b3-de5d-331b7af3c7b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples: 75879\n",
      "Total test samples: 1938\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "# -----------------------------\n",
    "# Load datasets\n",
    "# -----------------------------\n",
    "def load_sst2():\n",
    "    ds = load_dataset(\"glue\", \"sst2\")\n",
    "    return ds[\"train\"], ds[\"validation\"]\n",
    "\n",
    "def load_rotten():\n",
    "    ds = load_dataset(\"rotten_tomatoes\")\n",
    "    return ds[\"train\"], ds[\"test\"]\n",
    "\n",
    "sst2_train, sst2_test = load_sst2()\n",
    "rt_train, rt_test = load_rotten()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Convert datasets to (text,label)\n",
    "# -----------------------------\n",
    "def convert_sst2(sample):\n",
    "    return sample[\"sentence\"], int(sample[\"label\"])\n",
    "\n",
    "def convert_rotten(sample):\n",
    "    return sample[\"text\"], int(sample[\"label\"])\n",
    "\n",
    "train_pairs = [convert_sst2(x) for x in sst2_train] + \\\n",
    "              [convert_rotten(x) for x in rt_train]\n",
    "\n",
    "test_pairs  = [convert_sst2(x) for x in sst2_test] + \\\n",
    "              [convert_rotten(x) for x in rt_test]\n",
    "\n",
    "# Optional shuffle\n",
    "random.shuffle(train_pairs)\n",
    "random.shuffle(test_pairs)\n",
    "\n",
    "print(f\"Total train samples: {len(train_pairs)}\")\n",
    "print(f\"Total test samples: {len(test_pairs)}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset class\n",
    "# -----------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, label = self.data[idx]\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=False,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dynamic padding collate_fn\n",
    "# -----------------------------\n",
    "def collate_fn(batch):\n",
    "    input_ids = [b[\"input_ids\"] for b in batch]\n",
    "    labels = torch.tensor([b[\"labels\"] for b in batch])\n",
    "\n",
    "    max_len = max(len(ids) for ids in input_ids)\n",
    "    pad_id = tokenizer.pad_token_id\n",
    "\n",
    "    padded = torch.full((len(batch), max_len), pad_id)\n",
    "    for i, ids in enumerate(input_ids):\n",
    "        padded[i, :len(ids)] = ids\n",
    "\n",
    "    # attention mask: float\n",
    "    attention_mask = (padded != tokenizer.eos_token_id).float()\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": padded,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "685c08e0-67bf-426e-8bad-b7d2d7ac8242",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "685c08e0-67bf-426e-8bad-b7d2d7ac8242",
    "outputId": "aaba5492-3462-4d7c-d779-d69bf91bf2b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader batches: 4743\n",
      "Test loader batches: 122\n",
      "torch.Size([16, 39])\n",
      "torch.Size([16, 39])\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Create datasets\n",
    "# -----------------------------\n",
    "train_ds = SentimentDataset(train_pairs, tokenizer)\n",
    "test_ds = SentimentDataset(test_pairs, tokenizer)\n",
    "\n",
    "# -----------------------------\n",
    "# Create dataloaders\n",
    "# -----------------------------\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(\"Train loader batches:\", len(train_loader))\n",
    "print(\"Test loader batches:\", len(test_loader))\n",
    "\n",
    "# Optional: Inspect first batch\n",
    "example = next(iter(train_loader))\n",
    "print(example[\"input_ids\"].shape)\n",
    "print(example[\"attention_mask\"].shape)\n",
    "print(example[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92a3861d-1488-47b8-8eff-d36eb44f02f9",
   "metadata": {
    "id": "92a3861d-1488-47b8-8eff-d36eb44f02f9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "class GPT2EarlyExitClassifier(nn.Module):\n",
    "    def __init__(self, model_name, exit_layers, hyperparameters):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load GPT-2 as causal LM (we will use only hidden states)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            output_hidden_states=True,   # <-- IMPORTANT\n",
    "            return_dict=True\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        self.exit_layers = sorted(exit_layers)\n",
    "        self.hp = hyperparameters\n",
    "        self.num_labels = self.hp.get(\"num_labels\", 2)\n",
    "        dropout_rate = self.hp.get(\"dropout\", 0.0)\n",
    "\n",
    "        # Loss weights Î»_e for each exit\n",
    "        self.exit_loss_weights = self.hp.get(\n",
    "            \"exit_loss_weights\",\n",
    "            [1.0] * len(self.exit_layers)\n",
    "        )\n",
    "\n",
    "        hidden_size = self.model.config.hidden_size\n",
    "\n",
    "        # Create classification heads for each exit layer\n",
    "        self.exit_heads = nn.ModuleDict()\n",
    "        for layer in self.exit_layers:\n",
    "            self.exit_heads[str(layer)] = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(hidden_size, self.num_labels)\n",
    "            )\n",
    "\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        \"\"\"\n",
    "        Forward pass:\n",
    "        - Calls GPT-2 normally (causal mask automatically handled)\n",
    "        - Retrieves hidden_states for each layer\n",
    "        - Applies classifier at each exit layer\n",
    "        \"\"\"\n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "        # hidden_states is a tuple:\n",
    "        # [0] = embedding output\n",
    "        # [1] = layer 1 output\n",
    "        # ...\n",
    "        # [12] = last layer output  (if GPT2 base)\n",
    "        hidden_states = outputs.hidden_states\n",
    "\n",
    "        logits_dict = {}\n",
    "        total_loss = 0.0\n",
    "\n",
    "        # For each early exit\n",
    "        for i, layer in enumerate(self.exit_layers):\n",
    "\n",
    "            # hidden_states[layer] has shape [batch, seq_len, hidden_dim]\n",
    "            cls_vec = hidden_states[layer][:, -1, :]   # last token rep\n",
    "\n",
    "            logits = self.exit_heads[str(layer)](cls_vec)\n",
    "            logits_dict[layer] = logits\n",
    "\n",
    "            # Add weighted loss\n",
    "            if labels is not None:\n",
    "                weight = self.exit_loss_weights[i]\n",
    "                total_loss += weight * self.ce(logits, labels)\n",
    "\n",
    "        return {\n",
    "            \"loss\": total_loss if labels is not None else None,\n",
    "            \"logits\": logits_dict\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b706b3-305c-404f-ba74-2ef0782f9797",
   "metadata": {
    "id": "36b706b3-305c-404f-ba74-2ef0782f9797"
   },
   "outputs": [],
   "source": [
    "hyperparameter_grid = {\n",
    "    \"num_labels\": [2],                 # fixed\n",
    "    \"dropout\": [0.0],\n",
    "    \"exit_loss_weights\": [\n",
    "        [1, 1, 1, 1, 1, 1, 1]],\n",
    "\n",
    "    # training hyperparams\n",
    "    \"learning_rate\": [1e-5],\n",
    "    \"weight_decay\": [0.01],\n",
    "    \"num_epochs\": [1],\n",
    "    \"max_grad_norm\": [1.0],\n",
    "    \"batch_size\": [16],\n",
    "\n",
    "    # logging\n",
    "    \"log_every\": [500]\n",
    "}\n",
    "\n",
    "exit_layers = [3, 6, 9, 12, 15, 18, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a759cc13-cba0-4574-b7ed-91fea9c2c6c3",
   "metadata": {
    "id": "a759cc13-cba0-4574-b7ed-91fea9c2c6c3"
   },
   "outputs": [],
   "source": [
    "def make_experiment_name(hp):\n",
    "    return (\n",
    "        f\"lr{hp['learning_rate']}_\"\n",
    "        f\"wd{hp['weight_decay']}_\"\n",
    "        f\"ep{hp['num_epochs']}_\"\n",
    "        f\"drop{hp['dropout']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "DbTAstzAKKYQ",
   "metadata": {
    "id": "DbTAstzAKKYQ"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# NOTE: The GPT2EarlyExitClassifier class definition must be available (as provided by you)\n",
    "\n",
    "@torch.no_grad()\n",
    "def early_exit_eval(model_path, hyperparameters, exit_layers, data_loader, device, thresholds):\n",
    "    \"\"\"\n",
    "    Loads a trained GPT2EarlyExitClassifier and evaluates its efficiency\n",
    "    (Accuracy vs. Average Exit Depth) across multiple confidence thresholds\n",
    "    using batch processing.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the saved model checkpoint (e.g., './checkpoints/exp_name/epoch_X').\n",
    "        hyperparameters (dict): The original hyperparameters dictionary used for training.\n",
    "        exit_layers (list): The list of exit layers used (e.g., [3, 6, 9, 12, 15, 18, 21]).\n",
    "        data_loader (torch.utils.data.DataLoader): The evaluation data loader (e.g., test_loader).\n",
    "        device (str): 'cuda' or 'cpu'.\n",
    "        thresholds (list): List of confidence thresholds to test (e.g., [0.5, 0.7, 0.9]).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metrics for each tested threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n--- Loading Model from: {model_path} ---\")\n",
    "\n",
    "    # 1. Instantiate the Model Architecture (Re-building the frame)\n",
    "    model = GPT2EarlyExitClassifier(\n",
    "        model_name=\"gpt2-medium\",\n",
    "        exit_layers=exit_layers,\n",
    "        hyperparameters=hyperparameters\n",
    "    ).to(device)\n",
    "\n",
    "    # 2. Load the Model Weights (Filling the frame with trained weights)\n",
    "    try:\n",
    "        weights_path = os.path.join(model_path, 'pytorch_model.bin')\n",
    "        state_dict = torch.load(weights_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(\"Model weights loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL ERROR: Could not load model weights from {weights_path}.\")\n",
    "        print(e)\n",
    "        return {}\n",
    "\n",
    "    model.eval()\n",
    "    exit_layer_map = {layer: i + 1 for i, layer in enumerate(exit_layers)}\n",
    "    num_exits = len(exit_layers)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Define how to calculate the total cost/depth: The average layer number * processed samples\n",
    "    avg_cost_map = {layer: layer for layer in exit_layers}\n",
    "\n",
    "    for th in thresholds:\n",
    "        print(f\"\\nEvaluating Threshold: {th:.1f}\")\n",
    "\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        total_layers_used_sum = 0 # Sum of (exit_depth * samples_exited)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch in data_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            labels = batch[\"labels\"]\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            # 1. Run the forward pass to get all hidden states\n",
    "            # We must use the model's inner transformer for efficient evaluation\n",
    "            outputs = model.model(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                output_hidden_states=True,\n",
    "                return_dict=True\n",
    "            )\n",
    "            hidden_states = outputs.hidden_states\n",
    "\n",
    "            # Track which samples in the batch have already exited\n",
    "            batch_exited = torch.zeros(labels.size(0), dtype=torch.bool).to(device)\n",
    "\n",
    "            # 2. Check each exit layer sequentially for early stopping\n",
    "            for i, layer in enumerate(exit_layers):\n",
    "                current_exit_depth = i + 1 # 1st, 2nd, 3rd exit...\n",
    "\n",
    "                # Optimization: Stop loop if all samples have exited\n",
    "                if batch_exited.all():\n",
    "                    break\n",
    "\n",
    "                # Retrieve last token vector (CLS representation)\n",
    "                cls_vec = hidden_states[layer][:, -1, :]\n",
    "\n",
    "                # Apply classification head\n",
    "                logits = model.exit_heads[str(layer)](cls_vec)\n",
    "                probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "                confidences, preds = torch.max(probabilities, dim=-1)\n",
    "\n",
    "                # Identify samples that are ready to exit now\n",
    "                # Condition: Not already exited AND confidence > threshold\n",
    "                ready_to_exit = (~batch_exited) & (confidences >= th)\n",
    "\n",
    "                # If this is the LAST layer, force all remaining samples to exit\n",
    "                if current_exit_depth == num_exits:\n",
    "                    ready_to_exit = ~batch_exited\n",
    "\n",
    "                # 3. Update trackers for samples exiting in THIS step\n",
    "                if ready_to_exit.any():\n",
    "                    # Check accuracy for samples exiting NOW\n",
    "                    correct_predictions = (preds == labels)[ready_to_exit]\n",
    "                    correct += correct_predictions.sum().item()\n",
    "\n",
    "                    # Accumulate cost: depth * number of exiting samples\n",
    "                    total_layers_used_sum += (current_exit_depth * ready_to_exit.sum().item())\n",
    "\n",
    "                    # Mark these samples as exited\n",
    "                    batch_exited[ready_to_exit] = True\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        # 4. Calculate Final Metrics\n",
    "        inference_time = end_time - start_time\n",
    "\n",
    "        final_accuracy = correct / total_samples if total_samples > 0 else 0\n",
    "        avg_exit_depth = total_layers_used_sum / total_samples if total_samples > 0 else 0\n",
    "\n",
    "        results[f'threshold_{th}'] = {\n",
    "            \"accuracy\": final_accuracy,\n",
    "            \"avg_layers_used\": avg_exit_depth,\n",
    "            \"avg_latency_sec\": inference_time / total_samples if total_samples > 0 else 0,\n",
    "            \"cost_saving_pct\": 100 * (1 - (avg_exit_depth / num_exits)),\n",
    "            \"tokens_per_sec\": total_samples / inference_time if inference_time > 0 else 0 # Simplified token rate\n",
    "        }\n",
    "\n",
    "        print(f\"  Accuracy: {results[f'threshold_{th}']['accuracy']:.4f}\")\n",
    "        print(f\"  Avg Exit Depth (AED): {avg_exit_depth:.2f} / {num_exits}\")\n",
    "        print(f\"  Cost Savings: {results[f'threshold_{th}']['cost_saving_pct']:.2f}%\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b4418b9-cef6-4793-a1b6-204d5221105c",
   "metadata": {
    "id": "7b4418b9-cef6-4793-a1b6-204d5221105c"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad() # Disable gradient calculation for efficiency\n",
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the Early Exit Classifier on a dataset.\n",
    "    Reports average loss across all exits and (optional) basic accuracy.\n",
    "    \"\"\"\n",
    "    model.eval() # Set model to evaluation mode (disables dropout, etc.)\n",
    "    total_samples = 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Simple metric tracking for the final exit\n",
    "    correct_predictions = 0\n",
    "\n",
    "    print(\"--- Starting Evaluation ---\")\n",
    "\n",
    "    for step, batch in enumerate(data_loader):\n",
    "        # 1. Move batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        labels = batch[\"labels\"]\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # 2. Forward pass (returns loss and logits from all exits)\n",
    "        out = model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=labels # Pass labels to calculate the combined loss\n",
    "        )\n",
    "\n",
    "        # 3. Accumulate total loss\n",
    "        total_loss += out[\"loss\"].item()\n",
    "\n",
    "        # 4. Get predictions from the LAST exit layer (typically the best)\n",
    "        # Sort exit layers to ensure we always pick the highest/last index\n",
    "        last_exit_layer = sorted(model.exit_heads.keys(), key=int)[-1]\n",
    "\n",
    "        last_logits = out[\"logits\"][int(last_exit_layer)]\n",
    "\n",
    "        # Calculate predicted class (index with maximum logit)\n",
    "        predictions = torch.argmax(last_logits, dim=-1)\n",
    "\n",
    "        # 5. Accumulate correct predictions\n",
    "        correct_predictions += (predictions == labels).sum().item()\n",
    "\n",
    "    # 6. Calculate and print final metrics\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    print(f\"\\n--- Evaluation Results ---\")\n",
    "    print(f\"Avg Combined Loss (All Exits): {avg_loss:.4f}\")\n",
    "    print(f\"Accuracy (Final Exit Only): {accuracy:.4f}\")\n",
    "    print(\"--------------------------\\n\")\n",
    "\n",
    "    # Return metrics if needed for tracking best model\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1ef9a9a-9043-42f1-8a68-8973abbb19b2",
   "metadata": {
    "id": "d1ef9a9a-9043-42f1-8a68-8973abbb19b2"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, hp, device):\n",
    "\n",
    "    exp_name = make_experiment_name(hp)\n",
    "    epoch_history = []\n",
    "\n",
    "    # --- NEW: Identify the last exit layer here ---\n",
    "    # This must be done inside the function since the model object is passed in\n",
    "    last_exit_layer_key = sorted(model.exit_heads.keys(), key=int)[-1]\n",
    "    last_exit_layer_int = int(last_exit_layer_key)\n",
    "    # ---------------------------------------------\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=hp[\"learning_rate\"],\n",
    "        weight_decay=hp[\"weight_decay\"]\n",
    "    )\n",
    "\n",
    "    for epoch in range(hp[\"num_epochs\"]):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        total_train_correct = 0\n",
    "        total_train_samples = 0\n",
    "\n",
    "        for step, batch in enumerate(train_loader, start=1):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            out = model(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                labels=labels # Pass labels to calculate combined loss\n",
    "            )\n",
    "\n",
    "            loss = out[\"loss\"]\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # --- NEW: Calculate Accuracy for the current batch (using final exit) ---\n",
    "            total_train_samples += labels.size(0)\n",
    "\n",
    "            # Get logits from the last exit head\n",
    "            last_logits = out[\"logits\"][last_exit_layer_int]\n",
    "            predictions = torch.argmax(last_logits, dim=-1)\n",
    "            total_train_correct += (predictions == labels).sum().item()\n",
    "            # -----------------------------------------------------------------------\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), hp[\"max_grad_norm\"])\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % hp[\"log_every\"] == 0:\n",
    "                batch_accuracy = (predictions == labels).float().mean().item()\n",
    "                print(f\"Epoch {epoch+1} | Step {step} | Loss: {loss.item():.4f} | Acc: {batch_accuracy:.4f}\")\n",
    "\n",
    "        # --- Epoch End Metrics & Checkpointing ---\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_train_accuracy = total_train_correct / total_train_samples # CALCULATED HERE\n",
    "\n",
    "        print(f\"\\n>>> Epoch {epoch+1} completed | Avg Train Loss: {avg_train_loss:.4f} | Avg Train Acc: {avg_train_accuracy:.4f}\")\n",
    "\n",
    "        # Test Metrics (Evaluation)\n",
    "        final_test_loss, final_test_accuracy = evaluate(model, test_loader, device)\n",
    "\n",
    "        # 1. Capture ALL epoch data in a dictionary\n",
    "        epoch_metrics = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"train_accuracy\": avg_train_accuracy,\n",
    "            \"test_loss\": final_test_loss,\n",
    "            \"test_accuracy\": final_test_accuracy\n",
    "        }\n",
    "        epoch_history.append(epoch_metrics)\n",
    "\n",
    "        # 2. Save Checkpoint (with epoch number and dictionary)\n",
    "        base_dir = \"./checkpoints\"\n",
    "        exp_epoch_dir = os.path.join(base_dir, exp_name, f\"epoch_{epoch+1}\")\n",
    "\n",
    "        os.makedirs(exp_epoch_dir, exist_ok=True)\n",
    "\n",
    "        # A. Save model weights - ðŸ›‘ FIXED CODE HERE ðŸ›‘\n",
    "        weights_path = os.path.join(exp_epoch_dir, 'pytorch_model.bin')\n",
    "\n",
    "        # Save the state dictionary of your custom classifier\n",
    "        torch.save(model.state_dict(), weights_path)\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # The previous failed line: model.save_pretrained(exp_epoch_dir)\n",
    "        # ----------------------------------------------------\n",
    "\n",
    "        # B. Save the epoch metrics dictionary as a JSON file\n",
    "        with open(os.path.join(exp_epoch_dir, 'metrics.json'), 'w') as f:\n",
    "            json.dump(epoch_metrics, f, indent=4)\n",
    "\n",
    "        print(f\">>> Saved checkpoint and metrics to {exp_epoch_dir}\")\n",
    "\n",
    "    # Return the complete history (list of dictionaries)\n",
    "    return epoch_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da9484f0-a496-4b6d-8983-a2b237754639",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da9484f0-a496-4b6d-8983-a2b237754639",
    "outputId": "4c01ef31-9fc2-4dee-eebe-44370e00958a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "RUNNING EXPERIMENT: lr1e-05_wd0.01_ep1_drop0.0\n",
      "Hyperparameters: {'num_labels': 2, 'dropout': 0.0, 'exit_loss_weights': [1, 1, 1, 1, 1, 1, 1], 'learning_rate': 1e-05, 'weight_decay': 0.01, 'num_epochs': 1, 'max_grad_norm': 1.0, 'batch_size': 16, 'log_every': 500}\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Step 500 | Loss: 3.1239 | Acc: 0.8750\n",
      "Epoch 1 | Step 1000 | Loss: 1.7500 | Acc: 0.9375\n",
      "Epoch 1 | Step 1500 | Loss: 1.3683 | Acc: 1.0000\n",
      "Epoch 1 | Step 2000 | Loss: 3.7105 | Acc: 0.8750\n",
      "Epoch 1 | Step 2500 | Loss: 1.0042 | Acc: 0.9375\n",
      "Epoch 1 | Step 3000 | Loss: 1.2842 | Acc: 1.0000\n",
      "Epoch 1 | Step 3500 | Loss: 2.9863 | Acc: 0.8750\n",
      "Epoch 1 | Step 4000 | Loss: 0.6597 | Acc: 1.0000\n",
      "Epoch 1 | Step 4500 | Loss: 0.4745 | Acc: 1.0000\n",
      "\n",
      ">>> Epoch 1 completed | Avg Train Loss: 2.1614 | Avg Train Acc: 0.9039\n",
      "--- Starting Evaluation ---\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Avg Combined Loss (All Exits): 1.9902\n",
      "Accuracy (Final Exit Only): 0.9236\n",
      "--------------------------\n",
      "\n",
      ">>> Saved checkpoint and metrics to ./checkpoints/lr1e-05_wd0.01_ep1_drop0.0/epoch_1\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# generate all hyperparameter combinations\n",
    "keys = list(hyperparameter_grid.keys())\n",
    "values = list(hyperparameter_grid.values())\n",
    "\n",
    "all_experiment_results = {}\n",
    "\n",
    "for combo in itertools.product(*values):\n",
    "\n",
    "    hp = dict(zip(keys, combo))\n",
    "    hp[\"num_labels\"] = 2  # fixed\n",
    "\n",
    "    exp_name = make_experiment_name(hp)\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"RUNNING EXPERIMENT:\", exp_name)\n",
    "    print(\"Hyperparameters:\", hp)\n",
    "    print(\"==============================\")\n",
    "\n",
    "    # 1. Create fresh model for this configuration\n",
    "    model = GPT2EarlyExitClassifier(\n",
    "        model_name=\"gpt2-medium\",\n",
    "        exit_layers=exit_layers,\n",
    "        hyperparameters=hp\n",
    "    ).to(device)\n",
    "\n",
    "    # 2. Train\n",
    "    experiment_history = train(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        hp=hp,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Inside the outer loop, you capture the history list and extract the final metrics\n",
    "    final_metrics = experiment_history[-1]\n",
    "    final_test_accuracy = final_metrics['test_accuracy'] # Key is 'test_accuracy'\n",
    "    final_test_loss = final_metrics['test_loss']        # Key is 'test_loss'\n",
    "\n",
    "    # You then STORE the simplified results using the following keys:\n",
    "    all_experiment_results[exp_name] = {\n",
    "        \"hyperparameters\": hp,\n",
    "        \"history\": experiment_history,\n",
    "        \"final_test_accuracy\": final_test_accuracy, # Stored as 'final_test_accuracy'\n",
    "        \"final_test_loss\": final_test_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cutVDuJhIBuv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cutVDuJhIBuv",
    "outputId": "91975e17-1e32-4532-8f16-b8399eeb8f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "############################################\n",
      "HYPERPARAMETER SEARCH COMPLETE. FINDING BEST MODEL...\n",
      "############################################\n",
      "\n",
      "âœ… BEST MODEL FOUND: lr1e-05_wd0.01_ep1_drop0.0 (Epoch 1)\n",
      "   Max Test Accuracy: 0.9236\n",
      "   Checkpoint Path: ./checkpoints/lr1e-05_wd0.01_ep1_drop0.0/epoch_1\n",
      "\n",
      "--- Starting Final Early Exit Efficiency Evaluation ---\n",
      "\n",
      "--- Loading Model from: ./checkpoints/lr1e-05_wd0.01_ep1_drop0.0/epoch_1 ---\n",
      "Model weights loaded successfully.\n",
      "\n",
      "Evaluating Threshold: 0.5\n",
      "  Accuracy: 0.7890\n",
      "  Avg Exit Depth (AED): 1.00 / 7\n",
      "  Cost Savings: 85.71%\n",
      "\n",
      "Evaluating Threshold: 0.7\n",
      "  Accuracy: 0.8493\n",
      "  Avg Exit Depth (AED): 1.35 / 7\n",
      "  Cost Savings: 80.65%\n",
      "\n",
      "Evaluating Threshold: 0.8\n",
      "  Accuracy: 0.8782\n",
      "  Avg Exit Depth (AED): 1.64 / 7\n",
      "  Cost Savings: 76.52%\n",
      "\n",
      "Evaluating Threshold: 0.9\n",
      "  Accuracy: 0.9071\n",
      "  Avg Exit Depth (AED): 2.26 / 7\n",
      "  Cost Savings: 67.66%\n",
      "\n",
      "############################################\n",
      "FINAL EFFICIENCY RESULTS (Accuracy vs. Cost)\n",
      "############################################\n",
      "{\n",
      "    \"threshold_0.5\": {\n",
      "        \"accuracy\": 0.7889576883384933,\n",
      "        \"avg_layers_used\": 1.0,\n",
      "        \"avg_latency_sec\": 0.0029805400423221174,\n",
      "        \"cost_saving_pct\": 85.71428571428572,\n",
      "        \"tokens_per_sec\": 335.50966797980243\n",
      "    },\n",
      "    \"threshold_0.7\": {\n",
      "        \"accuracy\": 0.849329205366357,\n",
      "        \"avg_layers_used\": 1.3544891640866874,\n",
      "        \"avg_latency_sec\": 0.0030091959133482817,\n",
      "        \"cost_saving_pct\": 80.6501547987616,\n",
      "        \"tokens_per_sec\": 332.3146876426922\n",
      "    },\n",
      "    \"threshold_0.8\": {\n",
      "        \"accuracy\": 0.8782249742002064,\n",
      "        \"avg_layers_used\": 1.6434468524251806,\n",
      "        \"avg_latency_sec\": 0.0030101086210048114,\n",
      "        \"cost_saving_pct\": 76.52218782249743,\n",
      "        \"tokens_per_sec\": 332.21392511283784\n",
      "    },\n",
      "    \"threshold_0.9\": {\n",
      "        \"accuracy\": 0.9071207430340558,\n",
      "        \"avg_layers_used\": 2.263673890608875,\n",
      "        \"avg_latency_sec\": 0.0030575503505789457,\n",
      "        \"cost_saving_pct\": 67.66180156273036,\n",
      "        \"tokens_per_sec\": 327.0592092819176\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --- Code to execute AFTER the hyperparameter search loop is complete ---\n",
    "print(\"\\n\\n############################################\")\n",
    "print(\"HYPERPARAMETER SEARCH COMPLETE. FINDING BEST MODEL...\")\n",
    "print(\"############################################\")\n",
    "\n",
    "# 1. Identify the Best Model (based on final test accuracy)\n",
    "try:\n",
    "    best_exp_name = max(\n",
    "        all_experiment_results,\n",
    "        key=lambda name: all_experiment_results[name][\"final_test_accuracy\"]\n",
    "    )\n",
    "\n",
    "    best_result = all_experiment_results[best_exp_name]\n",
    "    best_hp = best_result[\"hyperparameters\"]\n",
    "    best_history = best_result[\"history\"]\n",
    "\n",
    "    # Find the epoch with the highest accuracy from the saved history\n",
    "    best_epoch_metrics = max(best_history, key=lambda x: x['test_accuracy'])\n",
    "    best_epoch_number = best_epoch_metrics['epoch']\n",
    "\n",
    "    # Construct the path to the best saved checkpoint\n",
    "    # NOTE: Assuming base_dir = \"./checkpoints\" for the path structure\n",
    "    BEST_CHECKPOINT_PATH = os.path.join(\n",
    "        \"./checkpoints\",\n",
    "        best_exp_name,\n",
    "        f\"epoch_{best_epoch_number}\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nâœ… BEST MODEL FOUND: {best_exp_name} (Epoch {best_epoch_number})\")\n",
    "    print(f\"   Max Test Accuracy: {best_epoch_metrics['test_accuracy']:.4f}\")\n",
    "    print(f\"   Checkpoint Path: {BEST_CHECKPOINT_PATH}\")\n",
    "\n",
    "except ValueError:\n",
    "    print(\"Error: The results dictionary is empty. Cannot determine best model.\")\n",
    "    exit()\n",
    "\n",
    "# 2. Run Early Exit Efficiency Evaluation\n",
    "# Define the thresholds and exit layers for the final test\n",
    "EVAL_THRESHOLDS = [0.5, 0.7, 0.8, 0.9]\n",
    "# Note: exit_layers must be defined globally or loaded from best_hp if it varied.\n",
    "\n",
    "print(\"\\n--- Starting Final Early Exit Efficiency Evaluation ---\")\n",
    "final_efficiency_results = early_exit_eval(\n",
    "    model_path=BEST_CHECKPOINT_PATH,\n",
    "    hyperparameters=best_hp,\n",
    "    exit_layers=exit_layers,\n",
    "    data_loader=test_loader, # Use the global test_loader\n",
    "    device=device,\n",
    "    thresholds=EVAL_THRESHOLDS\n",
    ")\n",
    "\n",
    "# 3. Output Final Results\n",
    "print(\"\\n############################################\")\n",
    "print(\"FINAL EFFICIENCY RESULTS (Accuracy vs. Cost)\")\n",
    "print(\"############################################\")\n",
    "print(json.dumps(final_efficiency_results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880b305-3df8-4e5e-bc8f-a308c4661a3f",
   "metadata": {
    "id": "3880b305-3df8-4e5e-bc8f-a308c4661a3f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a1c20-a2c1-49d5-9328-9584a770bf7c",
   "metadata": {
    "id": "cf1a1c20-a2c1-49d5-9328-9584a770bf7c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
