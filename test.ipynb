{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2730f4-0ca3-4436-8977-c8993f13024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer               \n",
    "\n",
    "from evaluation.evaluator import EarlyExitEvaluator\n",
    "from strategies.confidence_exit import ConfidenceExit\n",
    "from models.gpt2_wrapper import GPT2WithEarlyExit\n",
    "from evaluation.dataset_loaders.sst2 import load_sst2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5fedfd-4de9-43d3-9a9d-d66ccadce706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 50/50 [00:00<00:00, 50.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'accuracy', 'score': np.float64(0.74), 'avg_latency_sec': np.float64(0.019784612655639647), 'tokens_per_sec': 50.544330455463715, 'avg_layers_used': np.float64(6.34), 'num_samples': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# simple test one sentiment data\n",
    "strategy = ConfidenceExit(threshold=0.8, allowed_layers=[3,6,9])\n",
    "model = GPT2WithEarlyExit(\"gpt2\", strategy, tokenizer)\n",
    "\n",
    "dataset = load_sst2(number=50, task=\"train\")   # Number of data to use = 100, without kv \n",
    "\n",
    "evaluator = EarlyExitEvaluator(tokenizer)\n",
    "\n",
    "result = evaluator.evaluate(\n",
    "    model=model,\n",
    "    strategy=strategy,\n",
    "    dataset=dataset,\n",
    "    task_type=\"classification\",\n",
    "    dataset_name=\"sst2\",\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b9d7d-91f9-41f7-9c2f-ec62a0b7b19c",
   "metadata": {},
   "source": [
    "### KV-Cache Behavior in Early-Exit GPT-2 Wrapper\n",
    "\n",
    "Early-exit GPT-2 wrapper supports two execution modes depending on the task.\n",
    "KV-cache is handled differently for classification vs generation tasks.\n",
    "\n",
    "#### Classification Tasks (SST-2, AGNews) — No KV-Cache Used\n",
    "\n",
    "#### Generation Tasks (Summarization, Translation, QA)\n",
    "\n",
    "For generation, two modes depending on use_kv parameter. \n",
    "if use_kv = False (Full Recompute, slow mode)\n",
    "- Every new token recomputes all layers\n",
    "- Early exit only skips layers inside one forward pass\n",
    "- KV-cache is not stored\n",
    "- Useful for reproducing naive early-exit results\n",
    "\n",
    "if use_kv = True (KV Vached Early Exit, fast mode)\n",
    "- step 1: encode the prompt once and produce hidden states for the prompt, KV pair for every layer\n",
    "- step 2: decode tokens with early exit:\n",
    "    - for each token run layers sequenctiall..\n",
    "    - At each layer, compute confidence\n",
    "        - If early exit triggers at layer L:\n",
    "        - Layers 0..L compute normally and update KV\n",
    "        - Layers L+1..final are skipped\n",
    "        - Their KV is copied forward unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4aa213a-7eaf-42b7-88b9-635c937ca815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sst2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████| 1/1 [00:00<00:00, 23.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sst2 {'metric': 'accuracy', 'score': np.float64(1.0), 'avg_latency_sec': np.float64(0.04217815399169922), 'tokens_per_sec': 23.70895606756054, 'avg_layers_used': np.float64(4.0), 'num_samples': 1}\n",
      "Testing agnews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 15/15 [00:00<00:00, 44.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agnews {'metric': 'accuracy', 'score': np.float64(0.26666666666666666), 'avg_latency_sec': np.float64(0.02246535619099935), 'tokens_per_sec': 44.51298218902248, 'avg_layers_used': np.float64(5.2), 'num_samples': 15}\n",
      "Testing cnn_dm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Evaluating: 100%|███████████████████████████████| 22/22 [00:14<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_dm {'metric': 'rougeL', 'score': np.float64(0.05079575095102862), 'avg_latency_sec': np.float64(0.6509716402400624), 'tokens_per_sec': 1.5361652308405087, 'avg_layers_used': np.float64(4.051136363636363), 'num_samples': 22}\n",
      "Testing wmt14_enfr...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8931dda2a9284160a6b0024ed0c84a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8016ca362d5648d5a46075fe59bde2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████| 6/6 [00:03<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wmt14_enfr {'metric': 'bleu', 'score': np.float64(0.0), 'avg_latency_sec': np.float64(0.5234866937001547), 'tokens_per_sec': 1.910268230376043, 'avg_layers_used': np.float64(4.015625), 'num_samples': 6}\n",
      "Testing squad...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 21/21 [00:09<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squad {'metric': 'token_f1', 'score': np.float64(0.004896882945663434), 'avg_latency_sec': np.float64(0.4498912152789888), 'tokens_per_sec': 2.222759560619282, 'avg_layers_used': np.float64(4.017857142857143), 'num_samples': 21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### testing with KV similar to CALM paper\n",
    "from evaluation.dataset_loaders.sst2 import load_sst2\n",
    "from evaluation.dataset_loaders.agnews import load_agnews\n",
    "from evaluation.dataset_loaders.cnn_dm import load_cnndm\n",
    "from evaluation.dataset_loaders.squad import load_squad\n",
    "from evaluation.dataset_loaders.wmt_en_fr import load_wmt_enfr\n",
    "\n",
    "strategy = ConfidenceExit(threshold=0.7, allowed_layers=[3,6,9])\n",
    "model = GPT2WithEarlyExit(\"gpt2\", strategy, tokenizer, use_kv=\"True\")\n",
    "\n",
    "evaluator = EarlyExitEvaluator(tokenizer)\n",
    "\n",
    "datasets = [\n",
    "    (\"sst2\", load_sst2, \"classification\"),\n",
    "    (\"agnews\", load_agnews, \"classification\"),\n",
    "    (\"cnn_dm\", load_cnndm, \"summarization\"),\n",
    "    (\"wmt14_enfr\", load_wmt_enfr, \"translation\"),\n",
    "    (\"squad\", load_squad, \"qa\"),\n",
    "]\n",
    "\n",
    "for name, loader, task in datasets:\n",
    "    print(f\"Testing {name}...\")\n",
    "\n",
    "    dataset = loader(fraction=0.002)\n",
    "\n",
    "    # ---------- IMPORTANT: pass dataset_name for classification ----------\n",
    "    if task == \"classification\":\n",
    "        result = evaluator.evaluate(\n",
    "            model=model,\n",
    "            strategy=strategy,\n",
    "            dataset=dataset,\n",
    "            task_type=task,\n",
    "            dataset_name=name,      # e.g. \"sst2\" or \"agnews\"\n",
    "        )\n",
    "    else:\n",
    "        result = evaluator.evaluate(\n",
    "            model=model,\n",
    "            strategy=strategy,\n",
    "            dataset=dataset,\n",
    "            task_type=task,\n",
    "        )\n",
    "\n",
    "    print(name, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "358ea6ce-89cf-4288-ab0f-10232d52e2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sst2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████| 1/1 [00:00<00:00, 16.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sst2 {'metric': 'accuracy', 'score': np.float64(0.0), 'avg_latency_sec': np.float64(0.05985116958618164), 'tokens_per_sec': 16.7081112518623, 'avg_layers_used': np.float64(7.0), 'num_samples': 1}\n",
      "Testing agnews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 15/15 [00:00<00:00, 59.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agnews {'metric': 'accuracy', 'score': np.float64(0.13333333333333333), 'avg_latency_sec': np.float64(0.016642173131306965), 'tokens_per_sec': 60.08830650360303, 'avg_layers_used': np.float64(4.2), 'num_samples': 15}\n",
      "Testing cnn_dm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   9%|██▉                             | 2/22 [00:10<01:47,  5.39s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     28\u001b[39m     result = evaluator.evaluate(\n\u001b[32m     29\u001b[39m         model=model,\n\u001b[32m     30\u001b[39m         strategy=strategy,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m         dataset_name=name,      \u001b[38;5;66;03m# e.g. \"sst2\" or \"agnews\"\u001b[39;00m\n\u001b[32m     34\u001b[39m     )\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     result = \u001b[43mevaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(name, result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Efficient AI/Efficient AI Project/github/evaluation/evaluator.py:131\u001b[39m, in \u001b[36mEarlyExitEvaluator.evaluate\u001b[39m\u001b[34m(self, model, strategy, dataset, task_type, dataset_name, max_samples)\u001b[39m\n\u001b[32m    129\u001b[39m     pred_output = pred_label\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     pred_text, layers_used = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_with_early_exit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m     pred_output = pred_text\n\u001b[32m    134\u001b[39m latency = time.time() - t0\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Efficient AI/Efficient AI Project/github/models/gpt2_wrapper.py:163\u001b[39m, in \u001b[36mGPT2WithEarlyExit.generate_with_early_exit\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# For now, use the same implementation for both flags\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# (KV-optimized path can be added on top of this later)\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_new_tokens):\n\u001b[32m    160\u001b[39m \n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# Recompute full prefix up to this point, but only up to the EXIT layer\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# 1) embed with positions\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_with_pos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m     exited = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# 2) walk layers, check confidence at each, maybe exit early\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Efficient AI/Efficient AI Project/github/models/gpt2_wrapper.py:75\u001b[39m, in \u001b[36mGPT2WithEarlyExit._embed_with_pos\u001b[39m\u001b[34m(self, input_ids)\u001b[39m\n\u001b[32m     68\u001b[39m pos_ids = torch.arange(\n\u001b[32m     69\u001b[39m     \u001b[32m0\u001b[39m, seq_len,\n\u001b[32m     70\u001b[39m     dtype=torch.long,\n\u001b[32m     71\u001b[39m     device=\u001b[38;5;28mself\u001b[39m.device\n\u001b[32m     72\u001b[39m ).unsqueeze(\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# (1, T)\u001b[39;00m\n\u001b[32m     74\u001b[39m token_emb = \u001b[38;5;28mself\u001b[39m.model.transformer.wte(input_ids)      \u001b[38;5;66;03m# (1, T, d)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m pos_emb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_ids\u001b[49m\u001b[43m)\u001b[49m          \u001b[38;5;66;03m# (1, T, d)\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m token_emb + pos_emb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: index out of range in self"
     ]
    }
   ],
   "source": [
    "### testing without kv\n",
    "from evaluation.dataset_loaders.sst2 import load_sst2\n",
    "from evaluation.dataset_loaders.agnews import load_agnews\n",
    "from evaluation.dataset_loaders.cnn_dm import load_cnndm\n",
    "from evaluation.dataset_loaders.squad import load_squad\n",
    "from evaluation.dataset_loaders.wmt_en_fr import load_wmt_enfr\n",
    "\n",
    "strategy = ConfidenceExit(threshold=0.8, allowed_layers=[3,6,9])\n",
    "model = GPT2WithEarlyExit(\"gpt2\", strategy, tokenizer, use_kv=\"False\")\n",
    "\n",
    "evaluator = EarlyExitEvaluator(tokenizer)\n",
    "\n",
    "datasets = [\n",
    "    (\"sst2\", load_sst2, \"classification\"),\n",
    "    (\"agnews\", load_agnews, \"classification\"),\n",
    "    (\"cnn_dm\", load_cnndm, \"summarization\"),\n",
    "    (\"wmt14_enfr\", load_wmt_enfr, \"translation\"),\n",
    "    (\"squad\", load_squad, \"qa\"),\n",
    "]\n",
    "\n",
    "for name, loader, task in datasets:\n",
    "    print(f\"Testing {name}...\")\n",
    "\n",
    "    dataset = loader(fraction=0.002)\n",
    "\n",
    "    # pass dataset_name for classification\n",
    "    if task == \"classification\":\n",
    "        result = evaluator.evaluate(\n",
    "            model=model,\n",
    "            strategy=strategy,\n",
    "            dataset=dataset,\n",
    "            task_type=task,\n",
    "            dataset_name=name,      # e.g. \"sst2\" or \"agnews\"\n",
    "        )\n",
    "    else:\n",
    "        result = evaluator.evaluate(\n",
    "            model=model,\n",
    "            strategy=strategy,\n",
    "            dataset=dataset,\n",
    "            task_type=task,\n",
    "        )\n",
    "\n",
    "    print(name, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd20ad4-8d31-43a9-89c7-e9a04a5f988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing without kv\n",
    "strategy = ConfidenceExit(threshold=0.1, allowed_layers=[2,4,6,8,10])\n",
    "model = GPT2WithEarlyExit(\"gpt2\", strategy, tokenizer, use_kv=\"False\")\n",
    "\n",
    "evaluator = EarlyExitEvaluator(tokenizer)\n",
    "\n",
    "datasets = [\n",
    "    (\"sst2\", load_sst2, \"classification\"),\n",
    "    (\"agnews\", load_agnews, \"classification\"),\n",
    "    (\"cnn_dm\", load_cnndm, \"summarization\"),\n",
    "    (\"wmt14_enfr\", load_wmt_enfr, \"translation\"),\n",
    "    (\"squad\", load_squad, \"qa\"),\n",
    "]\n",
    "\n",
    "for name, loader, task in datasets:\n",
    "    print(f\"Testing {name}...\")\n",
    "\n",
    "    dataset = loader(fraction=0.002)\n",
    "\n",
    "    # pass dataset_name for classification\n",
    "    if task == \"classification\":\n",
    "        result = evaluator.evaluate(\n",
    "            model=model,\n",
    "            strategy=strategy,\n",
    "            dataset=dataset,\n",
    "            task_type=task,\n",
    "            dataset_name=name,      # e.g. \"sst2\" or \"agnews\"\n",
    "        )\n",
    "    else:\n",
    "        result = evaluator.evaluate(\n",
    "            model=model,\n",
    "            strategy=strategy,\n",
    "            dataset=dataset,\n",
    "            task_type=task,\n",
    "        )\n",
    "\n",
    "    print(name, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c24c4719-1561-4e8f-bb62-90f0eb4f37a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sst2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████| 4/4 [00:00<00:00, 53.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sst2 {'metric': 'accuracy', 'score': np.float64(0.75), 'avg_latency_sec': np.float64(0.01846897602081299), 'tokens_per_sec': 54.14485344899922, 'avg_layers_used': np.float64(3.0), 'num_samples': 4}\n",
      "Testing agnews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 38/38 [00:00<00:00, 75.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agnews {'metric': 'accuracy', 'score': np.float64(0.15789473684210525), 'avg_latency_sec': np.float64(0.013190169083444695), 'tokens_per_sec': 75.81403950728156, 'avg_layers_used': np.float64(3.0), 'num_samples': 38}\n",
      "Testing cnn_dm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 57/57 [00:32<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_dm {'metric': 'rougeL', 'score': np.float64(0.050215135413532744), 'avg_latency_sec': np.float64(0.5711161128261633), 'tokens_per_sec': 1.7509574279939475, 'avg_layers_used': np.float64(3.0), 'num_samples': 57}\n",
      "Testing wmt14_enfr...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7889bfb9bd7424ca0c9393adff68539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bdbcf5d4e34ea0a02f2fa2902eb46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 15/15 [00:05<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wmt14_enfr {'metric': 'bleu', 'score': np.float64(0.0), 'avg_latency_sec': np.float64(0.3851939678192139), 'tokens_per_sec': 2.596094652420253, 'avg_layers_used': np.float64(3.0), 'num_samples': 15}\n",
      "Testing squad...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 52/52 [00:18<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squad {'metric': 'token_f1', 'score': np.float64(0.005145796465739077), 'avg_latency_sec': np.float64(0.3616780317746676), 'tokens_per_sec': 2.7648900738959434, 'avg_layers_used': np.float64(3.0), 'num_samples': 52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### testing without kv\n",
    "strategy = ConfidenceExit(threshold=0.1, allowed_layers=[2,4,6,8,10])\n",
    "model = GPT2WithEarlyExit(\"gpt2\", strategy, tokenizer, use_kv=\"False\")\n",
    "\n",
    "evaluator = EarlyExitEvaluator(tokenizer)\n",
    "\n",
    "datasets = [\n",
    "    (\"sst2\", load_sst2, \"classification\"),\n",
    "    (\"agnews\", load_agnews, \"classification\"),\n",
    "    (\"cnn_dm\", load_cnndm, \"summarization\"),\n",
    "    (\"wmt14_enfr\", load_wmt_enfr, \"translation\"),\n",
    "    (\"squad\", load_squad, \"qa\"),\n",
    "]\n",
    "\n",
    "for name, loader, task in datasets:\n",
    "    print(f\"Testing {name}...\")\n",
    "\n",
    "    dataset = loader(fraction=0.005)\n",
    "\n",
    "    # pass dataset_name for classification\n",
    "    if task == \"classification\":\n",
    "        result = evaluator.evaluate(\n",
    "            model=model,\n",
    "            strategy=strategy,\n",
    "            dataset=dataset,\n",
    "            task_type=task,\n",
    "            dataset_name=name,      # e.g. \"sst2\" or \"agnews\"\n",
    "        )\n",
    "    else:\n",
    "        result = evaluator.evaluate(\n",
    "            model=model,\n",
    "            strategy=strategy,\n",
    "            dataset=dataset,\n",
    "            task_type=task,\n",
    "        )\n",
    "\n",
    "    print(name, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b21e3b-0642-4c6a-b557-dacd60caf463",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Strategy 2 - Confidence threshold should be (meet) in Continous layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1019086-7a15-4161-be7c-1c01ea7ff572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategies.continous_confidence_exit import ContinuousConfidenceExit\n",
    "\n",
    "strategy = ContinuousConfidenceExit(\n",
    "    threshold=0.75,\n",
    "    required_consecutive=2,\n",
    "    allowed_layers=[3, 6, 9, 11]\n",
    ")\n",
    "\n",
    "model = GPT2WithEarlyExit(\"gpt2\", strategy, tokenizer)\n",
    "evaluator = EarlyExitEvaluator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1257d5-01f6-4cfb-9706-41cbdae3ed5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
