{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2730f4-0ca3-4436-8977-c8993f13024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer               # <-- You forgot this import\n",
    "\n",
    "from evaluation.evaluator import EarlyExitEvaluator\n",
    "from strategies.confidence_exit import ConfidenceExit\n",
    "from models.gpt2_wrapper import GPT2WithEarlyExit\n",
    "from evaluation.dataset_loaders.sst2 import load_sst2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d5ab364-8869-4a49-ad40-4c448176d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = ConfidenceExit(threshold=1, allowed_layers=[3,6,9])\n",
    "model = GPT2WithEarlyExit(\"gpt2\", strategy, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b5fedfd-4de9-43d3-9a9d-d66ccadce706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████| 500/500 [00:19<00:00, 26.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'accuracy', 'score': np.float64(0.418), 'avg_latency_sec': np.float64(0.038216031074523926), 'tokens_per_sec': 26.167029172912546, 'avg_layers_used': np.float64(12.0), 'num_samples': 500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_sst2(number=500, task=\"train\")   # Number of data to use = 100 \n",
    "\n",
    "evaluator = EarlyExitEvaluator(tokenizer)\n",
    "\n",
    "result = evaluator.evaluate(\n",
    "    model=model,\n",
    "    strategy=strategy,\n",
    "    dataset=dataset,\n",
    "    task_type=\"classification\",\n",
    "    dataset_name=\"sst2\",\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa213a-7eaf-42b7-88b9-635c937ca815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sst2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████| 87/87 [00:03<00:00, 23.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sst2 {'metric': 'accuracy', 'score': np.float64(0.4367816091954023), 'avg_latency_sec': np.float64(0.04162762082856277), 'tokens_per_sec': 24.022511498275456, 'avg_layers_used': np.float64(12.0), 'num_samples': 87}\n",
      "Testing agnews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████| 760/760 [00:36<00:00, 20.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agnews {'metric': 'accuracy', 'score': np.float64(0.2723684210526316), 'avg_latency_sec': np.float64(0.04812421390884801), 'tokens_per_sec': 20.77956020007097, 'avg_layers_used': np.float64(12.0), 'num_samples': 760}\n",
      "Testing cnn_dm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Evaluating:  16%|████▌                       | 186/1149 [00:53<03:43,  4.30it/s]"
     ]
    }
   ],
   "source": [
    "from evaluation.dataset_loaders.sst2 import load_sst2\n",
    "from evaluation.dataset_loaders.agnews import load_agnews\n",
    "from evaluation.dataset_loaders.cnn_dm import load_cnndm\n",
    "from evaluation.dataset_loaders.squad import load_squad\n",
    "from evaluation.dataset_loaders.wmt_en_fr import load_wmt_enfr\n",
    "\n",
    "datasets = [\n",
    "    (\"sst2\", load_sst2, \"classification\"),\n",
    "    (\"agnews\", load_agnews, \"classification\"),\n",
    "    (\"cnn_dm\", load_cnndm, \"summarization\"),\n",
    "    (\"wmt14_enfr\", load_wmt_enfr, \"translation\"),\n",
    "    (\"squad\", load_squad, \"qa\"),\n",
    "]\n",
    "\n",
    "for name, loader, task in datasets:\n",
    "    print(f\"Testing {name}...\")\n",
    "\n",
    "    dataset = loader(fraction=0.10)\n",
    "\n",
    "    # ---------- IMPORTANT: pass dataset_name for classification ----------\n",
    "    if task == \"classification\":\n",
    "        result = evaluator.evaluate(\n",
    "            model=model,\n",
    "            strategy=strategy,\n",
    "            dataset=dataset,\n",
    "            task_type=task,\n",
    "            dataset_name=name,      # e.g. \"sst2\" or \"agnews\"\n",
    "        )\n",
    "    else:\n",
    "        result = evaluator.evaluate(\n",
    "            model=model,\n",
    "            strategy=strategy,\n",
    "            dataset=dataset,\n",
    "            task_type=task,\n",
    "        )\n",
    "\n",
    "    print(name, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b21e3b-0642-4c6a-b557-dacd60caf463",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Strategy 2 - Confidence threshold should be (meet) in Continous layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1019086-7a15-4161-be7c-1c01ea7ff572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategies.continous_confidence_exit import ContinuousConfidenceExit\n",
    "\n",
    "strategy = ContinuousConfidenceExit(\n",
    "    threshold=0.75,\n",
    "    required_consecutive=2,\n",
    "    allowed_layers=[3, 6, 9, 11]\n",
    ")\n",
    "\n",
    "model = GPT2WithEarlyExit(\"gpt2\", strategy, tokenizer)\n",
    "evaluator = EarlyExitEvaluator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbedc094-b088-423b-83d2-c32406c6f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (\"sst2\", load_sst2, \"classification\"),\n",
    "    (\"agnews\", load_agnews, \"classification\"),\n",
    "    (\"cnn_dm\", load_cnndm, \"summarization\"),\n",
    "    (\"wmt14_enfr\", load_wmt_enfr, \"translation\"),\n",
    "    (\"squad\", load_squad, \"qa\"),\n",
    "]\n",
    "\n",
    "for name, loader, task in datasets:\n",
    "    print(f\"\\n========== Testing {name.upper()} ==========\\n\")\n",
    "\n",
    "    # Use 2% of dataset\n",
    "    dataset = loader(fraction=0.02)\n",
    "\n",
    "    result = evaluator.evaluate(\n",
    "        model=model,\n",
    "        strategy=strategy,\n",
    "        dataset=dataset,\n",
    "        task_type=task,\n",
    "    )\n",
    "\n",
    "    print(name, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1257d5-01f6-4cfb-9706-41cbdae3ed5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
